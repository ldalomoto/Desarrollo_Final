#from gpt4all import GPT4All
#
#MODEL_NAME = "mistral-7b-instruct-v0.1.Q4_0.gguf"
#
#model = GPT4All(MODEL_NAME)
#
#def run_llm(prompt: str, max_tokens=500, temp=0.2) -> str:
#    with model.chat_session():
#        return model.generate(
#            prompt=prompt,
#            max_tokens=max_tokens,
#            temp=temp
#        )
