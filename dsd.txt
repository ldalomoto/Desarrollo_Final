import os
import json
from google import genai
from dotenv import load_dotenv

load_dotenv()

client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))

MODEL_NAME = "gemini-2.5-flash-lite"

LOCATION_SCHEMA = {
    "type": "object",
    "properties": {
        "incident_types": {
            "type": "array",
            "items": {"type": "string"}
        },
        "location_candidates": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "name": {"type": "string"},
                    "city": {"type": "string"},
                    "country": {"type": "string"},

                    "place_type": {
                        "type": "string",
                        "enum": [
                            "barrio",
                            "parroquia",
                            "calle",
                            "avenida",
                            "punto_de_referencia",
                            "zona_general"
                        ]
                    },

                    "precision": {
                        "type": "string",
                        "enum": [
                            "alta",
                            "media",
                            "baja"
                        ]
                    },

                    "reasoning": {"type": "string"}
                },
                "required": [
                    "name",
                    "city",
                    "country",
                    "place_type",
                    "precision",
                    "reasoning"
                ]
            }
        }
    },
    "required": ["incident_types", "location_candidates"]
}


LOCATION_PROMPT = """
Analiza la siguiente noticia de inseguridad ciudadana.

Extrae los tipos de incidentes y los lugares mencionados.

REGLAS IMPORTANTES:
- Si el texto menciona "sector", "barrio" o "zona", clasifica el lugar como BARRIO.
- Si menciona "parroquia", clasifícalo como PARROQUIA.
- Si menciona "calle", "avenida" o "av.", clasifícalo como CALLE o AVENIDA.
- No confundas barrios con calles.
- Barrios históricos de Quito como La Marín, San Roque, La Tola
  deben clasificarse como BARRIO.

No inventes coordenadas.
No hagas suposiciones fuera del texto.
Responde exclusivamente con JSON válido.
"""


def infer_location(text: str) -> dict:
    response = client.models.generate_content(
        model=MODEL_NAME,
        contents=LOCATION_PROMPT + "\n\n" + text,
        config={
            "response_mime_type": "application/json",
            "response_schema": LOCATION_SCHEMA,
            "temperature": 0.2
        }
    )

    try:
        return json.loads(response.text)
    except json.JSONDecodeError as e:
        raise ValueError(
            f"Gemini devolvió una respuesta inválida:\n{response.text}"
        ) from e





#######################################################################################




import json
import re
from core.llm import run_llm

LOCATION_PROMPT = """
Analiza cuidadosamente la siguiente noticia de inseguridad ciudadana.

OBJETIVO:
Extraer los tipos de incidentes y determinar la ubicación MÁS ESPECÍFICA posible.

Devuelve SOLO JSON válido con esta estructura:

{
  "incident_types": ["string"],
  "location_candidates": [
    {
      "name": "string",
      "city": "string",
      "country": "Ecuador",
      "place_type": "barrio | parroquia | calle | avenida | punto_de_referencia | zona_general",
      "precision": "alta | media | baja",
      "reasoning": "string"
    }
  ]
}
"""

def clean_json(text: str) -> str:
    start = text.find("{")
    end = text.rfind("}")

    if start == -1 or end == -1:
        raise ValueError("No se encontró JSON en la respuesta del modelo")

    text = text[start:end + 1]

    text = text.replace("\\_", "_")
    text = text.replace("\\-", "-")
    text = text.replace("\\'", "'")

    text = re.sub(r"[\x00-\x1F\x7F]", "", text)

    return text

def infer_location(text: str) -> dict:
    prompt = LOCATION_PROMPT + "\n\nNOTICIA:\n" + text

    response = run_llm(prompt, max_tokens=700)

    with open("llm_raw_response.txt", "w", encoding="utf-8") as f:
        f.write(response)

    cleaned = clean_json(response)

    try:
        data = json.loads(cleaned)

        if "location_candidates" not in data:
            raise ValueError("Respuesta sin location_candidates")

        return data

    except json.JSONDecodeError as e:
        raise ValueError(
            f"JSON inválido devuelto por el modelo:\n{cleaned}"
        ) from e